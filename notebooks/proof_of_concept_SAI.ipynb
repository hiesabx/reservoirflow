{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas 1:\n",
    "1. first we need to convert our sparse matrix to dense matrix where each row is an example by keeping only the diagonals.\n",
    "2. Change in Shapes:\n",
    "   1. for 1D models: \n",
    "      1. the shape will change from (nxn) to (nx3) since each cell has 3 terms (i.e. 2 neighbors and the cell itself). \n",
    "      2. Formulation:\n",
    "         1.  b, c1, c2 x x1 > b1\n",
    "         2. c1, c2, c3 x x2 > b2\n",
    "         3. c2, c3, c4 x x3 > b3\n",
    "         4. c3, c4, b  x x4 > b4\n",
    "   2. for 2D models: \n",
    "      1. the shape will change from (nxn) to (nx5) since each cell has 5 terms (i.e. 4 neighbors and the cell itself).  \n",
    "   3. for 3D models:\n",
    "      1. the shape will change from (nxn) to (nx7) since each cell has 7 terms (i.e. 6 neighbors and the cell itself).\n",
    "\n",
    "Idea 2: Train neural network to calc A^-1 then use that to get x: A^-1.b = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openresim as ors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    grid = ors.grids.Cartesian(\n",
    "        nx=4, ny=1, nz=1, dx=300, dy=350, dz=40, phi=0.27, kx=270, dtype=\"double\"\n",
    "    )\n",
    "    fluid = ors.fluids.SinglePhase(mu=0.5, B=1, dtype=\"double\")\n",
    "    model = ors.models.Model(grid, fluid, dtype=\"double\", verbose=False)\n",
    "    model.set_well(id=4, q=-600, s=1.5, r=3.5)\n",
    "    model.set_boundaries({0: (\"pressure\", 4000), 5: (\"rate\", 0)})\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell 1: {p1: 85.2012000000000, p2: -28.4004000000000}\n",
      "cell 2: {p1: 28.4004000000000, p3: 28.4004000000000, p2: -56.8008000000000}\n",
      "cell 3: {p2: 28.4004000000000, p4: 28.4004000000000, p3: -56.8008000000000}\n",
      "cell 4: {p3: 28.4004000000000, p4: -28.4004000000000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f\"cell {k}: {dict(v[0])}\") for k, v in model.get_cells_eq().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, d = model.get_matrices_vectorized(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4000.,   nan,   nan,   nan,   nan,   nan]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pressures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Simulation run started: 3 timesteps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|\u001b[32m███▎      \u001b[0m| 1/3 [00:00<00:00,  6.57steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "[[ 85.2012 -28.4004   0.       0.    ]\n",
      " [ 28.4004 -56.8008  28.4004   0.    ]\n",
      " [  0.      28.4004 -56.8008  28.4004]\n",
      " [  0.       0.      28.4004 -28.4004]\n",
      " [-85.2012  28.4004   0.       0.    ]\n",
      " [ 28.4004 -56.8008  28.4004   0.    ]\n",
      " [  0.      28.4004 -56.8008  28.4004]\n",
      " [  0.       0.      28.4004 -28.4004]\n",
      " [170.4024 -56.8008   0.       0.    ]\n",
      " [  0.       0.       0.       0.    ]\n",
      " [  0.       0.       0.       0.    ]\n",
      " [  0.       0.       0.       0.    ]]\n",
      "[[ 227203.2 -227203.2  454406.4]\n",
      " [      0.        0.        0. ]\n",
      " [      0.        0.        0. ]\n",
      " [    600.      600.        0. ]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|\u001b[32m██████▋   \u001b[0m| 2/3 [00:00<00:00,  6.57steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1\n",
      "[[ 85.2012 -28.4004   0.       0.    ]\n",
      " [ 28.4004 -56.8008  28.4004   0.    ]\n",
      " [  0.      28.4004 -56.8008  28.4004]\n",
      " [  0.       0.      28.4004 -28.4004]\n",
      " [-85.2012  28.4004   0.       0.    ]\n",
      " [ 28.4004 -56.8008  28.4004   0.    ]\n",
      " [  0.      28.4004 -56.8008  28.4004]\n",
      " [  0.       0.      28.4004 -28.4004]\n",
      " [170.4024 -56.8008   0.       0.    ]\n",
      " [  0.       0.       0.       0.    ]\n",
      " [  0.       0.       0.       0.    ]\n",
      " [  0.       0.       0.       0.    ]]\n",
      "[[ 227203.2 -227203.2  454406.4]\n",
      " [      0.        0.        0. ]\n",
      " [      0.        0.        0. ]\n",
      " [    600.      600.        0. ]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 3/3 [00:00<00:00,  6.68steps/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2\n",
      "[[ 85.2012 -28.4004   0.       0.    ]\n",
      " [ 28.4004 -56.8008  28.4004   0.    ]\n",
      " [  0.      28.4004 -56.8008  28.4004]\n",
      " [  0.       0.      28.4004 -28.4004]\n",
      " [-85.2012  28.4004   0.       0.    ]\n",
      " [ 28.4004 -56.8008  28.4004   0.    ]\n",
      " [  0.      28.4004 -56.8008  28.4004]\n",
      " [  0.       0.      28.4004 -28.4004]\n",
      " [170.4024 -56.8008   0.       0.    ]\n",
      " [  0.       0.       0.       0.    ]\n",
      " [  0.       0.       0.       0.    ]\n",
      " [  0.       0.       0.       0.    ]]\n",
      "[[ 227203.2 -227203.2  454406.4]\n",
      " [      0.        0.        0. ]\n",
      " [      0.        0.        0. ]\n",
      " [    600.      600.        0. ]]\n",
      "\n",
      "[info] Simulation run of 3 steps finished in 0.45 seconds.\n",
      "\n",
      "[info] Material Balance Error: 1.693933882052079e-11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.run(\n",
    "        nsteps=3,\n",
    "        sparse=False,\n",
    "        threading=False,\n",
    "        vectorize=False,\n",
    "        check_MB=True,\n",
    "        print_arrays=True,\n",
    "        isolver=\"cgs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps</th>\n",
       "      <th>Time</th>\n",
       "      <th>cells_id</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3989.436768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3989.436768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3989.436768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3968.310305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3968.310305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3968.310305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3947.183842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3947.183842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3947.183842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3926.057379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3926.057379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3926.057379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    steps  Time  cells_id     pressure\n",
       "0       1     1         1  3989.436768\n",
       "1       2     2         1  3989.436768\n",
       "2       3     3         1  3989.436768\n",
       "3       1     1         2  3968.310305\n",
       "4       2     2         2  3968.310305\n",
       "5       3     3         2  3968.310305\n",
       "6       1     1         3  3947.183842\n",
       "7       2     2         3  3947.183842\n",
       "8       3     3         3  3947.183842\n",
       "9       1     1         4  3926.057379\n",
       "10      2     2         4  3926.057379\n",
       "11      3     3         4  3926.057379"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_data(\n",
    "    boundary=False,\n",
    "    units=False,\n",
    "    drop_nan=True,\n",
    "    # drop_zero=True,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_id = model.grid.get_cells_id(False, False, \"array\")\n",
    "cells_id_nsteps = np.array([cells_id]*model.nsteps).reshape(-1,1)\n",
    "cells_nsteps = np.repeat(np.arange(1, model.nsteps+1), model.n).reshape(-1,1)\n",
    "x = np.concatenate([cells_nsteps, cells_id_nsteps], axis=1)\n",
    "y = model.pressures[1:, cells_id].reshape(-1,1)\n",
    "data = np.concatenate([x,y], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pressures.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([\n",
    "    np.concatenate([[0], np.diag(A, -1)]).reshape(-1,1),\n",
    "    np.diag(A, 0).reshape(-1,1),\n",
    "    np.concatenate([np.diag(A, 1), [0]]).reshape(-1,1)],\n",
    "    axis=1\n",
    ")\n",
    "df = pd.DataFrame()\n",
    "df['L'] = np.concatenate([[0], np.diag(A, -1)])\n",
    "df['C'] = np.diag(A, 0)\n",
    "df['R'] = np.concatenate([np.diag(A, 1), [0]])\n",
    "df['B'] = -d\n",
    "# df['P_t0'] = model.pressures[0, 1:-1]\n",
    "# df['P_t1'] = model.pressures[1, 1:-1]\n",
    "df['P_L'] = model.pressures[1, 0:-2]\n",
    "df['P_C'] = model.pressures[1, 1:-1]\n",
    "df['P_R'] = model.pressures[1, 2:]\n",
    "df.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "# df.iloc[0, :2] = [56.8008, 28.4004]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['id', 'tstep', 'p'])\n",
    "df = pd.DataFrame(columns=['id'])\n",
    "n = model.grid.get_n(False)\n",
    "id = pd.Series(model.grid.cells_id, name='id')\n",
    "print(id)\n",
    "tstep = range(model.tstep)\n",
    "for t in tstep:\n",
    "    df_t = pd.DataFrame([id, [t]*n, model.pressures[:, id].flatten()], \n",
    "                        columns=df.columns)\n",
    "    print((n*t),n+(n*t))\n",
    "    df.loc[(n*t):n+(n*t)+1, 'id'] = id#, t, model.pressures[:, id].flatten()]\n",
    "    # df.append(id)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantValueConstraint(tf.keras.constraints.Constraint):\n",
    "  \"\"\"Constrains the elements of the tensor to `value`.\n",
    "  https://stackoverflow.com/questions/65484696/set-only-the-bias-to-be-non-trainable-in-tensorflow-keras\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, value):\n",
    "    self.value = value\n",
    "\n",
    "  def __call__(self, w):\n",
    "    return w * 0 + self.value\n",
    "\n",
    "  def get_config(self):\n",
    "    return {'value': self.value}\n",
    "  \n",
    "from keras.constraints import nonneg\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "class Between(tf.keras.constraints.Constraint):\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  https://stackoverflow.com/a/56822471/11549398\n",
    "  \"\"\"\n",
    "  def __init__(self, min_value, max_value):\n",
    "      self.min_value = min_value\n",
    "      self.max_value = max_value\n",
    "\n",
    "  def __call__(self, w):        \n",
    "      return K.clip(w, self.min_value, self.max_value)\n",
    "\n",
    "  def get_config(self):\n",
    "      return {'min_value': self.min_value,\n",
    "              'max_value': self.max_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for 1D:\n",
    "r = 1\n",
    "bias_weights = df.loc[r, 'B']\n",
    "# kernel_weights = df.loc[r, ['L','C','R']].values.transpose()\n",
    "kernel_weights = df.loc[r, ['P_L','P_C','P_R']].values.transpose()\n",
    "x0 = keras.Input(shape=(3,), name='input')\n",
    "x = keras.layers.Dense(1,   \n",
    "        use_bias=True,\n",
    "        bias_initializer=tf.keras.initializers.Constant(bias_weights), \n",
    "        bias_constraint=ConstantValueConstraint(bias_weights),\n",
    "        kernel_initializer=tf.keras.initializers.Constant(kernel_weights), \n",
    "        kernel_constraint=Between(min_value=0.0, max_value=4000),\n",
    "        name='layer_1')(x0)\n",
    "nn_model = keras.Model(inputs=x0, outputs=x)\n",
    "print('Weights: ')\n",
    "print(nn_model.weights)\n",
    "\n",
    "print('Result: should be zero!')\n",
    "nn_model.predict(df.loc[r, ['L','C','R']].values[np.newaxis])\n",
    "# nn_model.predict(df.loc[r, ['P_L','P_C','P_R']].values[np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for 1D Conv:\n",
    "r = 0\n",
    "bias_weights = df.loc[r, 'B']\n",
    "# kernel_weights = df.loc[:, ['L','C','R']].values\n",
    "kernel_weights = df.loc[r, ['P_L','P_C','P_R']].values\n",
    "\n",
    "x0 = keras.Input(shape=(3,1), name='input')\n",
    "x = keras.layers.Conv1D(1, \n",
    "                        kernel_size=(3,),\n",
    "                        strides=1,\n",
    "                        kernel_initializer=tf.keras.initializers.Constant(kernel_weights),\n",
    "                        # bias_initializer=tf.keras.initializers.Constant(bias_weights),\n",
    "                        # bias_constraint=ConstantValueConstraint(bias_weights),\n",
    "                        kernel_constraint=Between(min_value=0.0, max_value=4000),\n",
    "                        use_bias=True)(x0)\n",
    "# x = keras.layers.Dense(1, \n",
    "#                     use_bias=False,\n",
    "#                     kernel_initializer=tf.keras.initializers.Constant(1))(x)\n",
    "nn_model = keras.Model(inputs=x0, outputs=x)\n",
    "print('Weights: ')\n",
    "print(nn_model.weights)\n",
    "\n",
    "print('Result: should be zero!')\n",
    "nn_model.predict(df.loc[r, ['L','C','R']].values.flatten()[np.newaxis])\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=100)\n",
    "nn_model.compile(opt, 'MSE')\n",
    "nn_model.fit(\n",
    "    df.loc[:, ['L','C','R']].values, \n",
    "    df.loc[:, ['B']].values,\n",
    "    # df.loc[:, ['P_C']].values.flatten()[np.newaxis],\n",
    "    batch_size=1,\n",
    "    epochs=100,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Result: should be zero!')\n",
    "nn_model.predict(df.iloc[:, 0:3].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 4\n",
    "bias = np.array(df.loc[:r, 'B'])\n",
    "x0 = keras.Input(shape=(3,1), name='input')\n",
    "x = keras.layers.Conv1D(3, \n",
    "                        kernel_size=(1,),\n",
    "                        use_bias=False)(x0)\n",
    "x = keras.layers.Dense(1, \n",
    "                    use_bias=False)(x)\n",
    "# x = keras.layers.Dense(4,   \n",
    "#         use_bias=True,\n",
    "#         bias_initializer=tf.keras.initializers.Constant(df.loc[:r, 'B']), \n",
    "#         bias_constraint=ConstantValueConstraint(df.loc[:r, 'B']),\n",
    "#         kernel_constraint=nonneg(),\n",
    "#         name='layer_1')(x)\n",
    "nn_model = keras.Model(inputs=x0, outputs=x)\n",
    "nn_model.weights\n",
    "# x2 = keras.layers.Dense(1, \n",
    "#         # use_bias=True,\n",
    "#         # kernel_constraint=nonneg(),\n",
    "#         name='layer_2')(x1)\n",
    "# nn_model = keras.Model(inputs=x0, outputs=x2)\n",
    "# nn_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.get_layer('layer_1').set_weights([\n",
    "    # nn_model.get_layer('layer_1').get_weights()[0],\n",
    "    # np.array([4000,3999,3998]).reshape(-1,1),\n",
    "    # df.loc[:r, ['L','C','R']].values.transpose(),\n",
    "    np.array(df.loc[:r, 'B']),\n",
    "])\n",
    "nn_model.get_layer('layer_2').set_weights([\n",
    "    np.array(df.loc[:r, 'B']).reshape(-1, 1),\n",
    "    # np.array([4000,3999,3998]).reshape(-1,1),\n",
    "    # df.loc[r, ['L','C','R']].values.reshape(-1,1),\n",
    "    np.array([1]),\n",
    "])\n",
    "nn_model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ad = np.concatenate([A,d], axis=1)\n",
    "Ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACT_LST = [None, 'linear', 'sigmoid', 'relu', 'tanh']\n",
    "FLT_LST = [5, 10, 20, 20, 5, 1]\n",
    "IN_SHAPE = Ad.shape[1]\n",
    "\n",
    "def AutoEncoder(\n",
    "    input_shape = (IN_SHAPE,),\n",
    "    filters= FLT_LST,\n",
    "    activation_function = ACT_LST[-1], \n",
    "    dropout = False,\n",
    "    dropout_rate = 0.2,\n",
    "):\n",
    "    \"\"\"Create keras autoencoder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : Tuple[int], optional\n",
    "        _description_, by default (X.shape[1],)\n",
    "    filters : List[int], optional\n",
    "        _description_, by default [64, 32, 16, 3]\n",
    "    activation_function : str, optional\n",
    "        _description_, by default ACT_LST[2]\n",
    "    dropout : bool, optional\n",
    "        _description_, by default False\n",
    "    dropout_rate : float, optional\n",
    "        _description_, by default 0.1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    input = keras.Input(shape=input_shape)\n",
    "    for i, filter in enumerate(filters):\n",
    "        if i == 0:\n",
    "            x = tf.keras.layers.Dense(filter, activation=activation_function)(input)\n",
    "            if dropout:\n",
    "                x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "        elif i < len(filters) - 1:\n",
    "            x = tf.keras.layers.Dense(filter, activation=activation_function)(x)\n",
    "            if dropout:\n",
    "                x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "        else:\n",
    "            compressed = tf.keras.layers.Dense(filter, activation=activation_function)(x)\n",
    "    for i, filter in enumerate(filters[:-1][::-1]):\n",
    "        if i == 0:\n",
    "            x = tf.keras.layers.Dense(filter, activation=activation_function)(compressed)\n",
    "            if dropout:\n",
    "                x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "        else:\n",
    "            x = tf.keras.layers.Dense(filter, activation=activation_function)(x)\n",
    "            if dropout:\n",
    "                x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "        decompressed = tf.keras.layers.Dense(input_shape[0], activation=activation_function)(x)\n",
    "\n",
    "    autoencoder = keras.Model(input, decompressed, name='autoencoder')\n",
    "    encoder = keras.Model(input, compressed, name='encoder')\n",
    "\n",
    "    compressed_input = keras.Input(shape=(filters[-1],))\n",
    "    bottleneck_id = -(len(filters)*2)+1 if dropout else -(len(filters))\n",
    "    for i, layer in enumerate(autoencoder.layers[bottleneck_id:]):\n",
    "        if i == 0:\n",
    "            decoder_layer = layer(compressed_input)\n",
    "        else:\n",
    "            decoder_layer = layer(decoder_layer)\n",
    "    decoder = keras.Model(compressed_input, decoder_layer, name='decoder')\n",
    "    # Adam, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "    opt = keras.optimizers.Adam(learning_rate=10)\n",
    "    encoder.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    decoder.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    autoencoder.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return autoencoder, encoder, decoder\n",
    "\n",
    "autoencoder, encoder, decoder = AutoEncoder()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "epochs = 300\n",
    "eval_freq = 50\n",
    "results = {'train_loss':[], 'train_mse':[],\n",
    "               'test_loss':[], 'test_mse':[],\n",
    "               'n_way_train_acc':[], 'n_way_test_acc':[]}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    outputs = encoder.fit(Ad, model.pressures[-1, 1:-1],\n",
    "                epochs=1,\n",
    "                batch_size=5,\n",
    "                shuffle=False,\n",
    "                verbose=0,\n",
    "                validation_data=(Ad, model.pressures[-1, 1:-1]))\n",
    "    \n",
    "    if epoch % eval_freq == 0:\n",
    "        results['train_loss'].append(outputs.history['loss'][0])\n",
    "        results['train_mse'].append(outputs.history['mean_squared_error'][0])\n",
    "        results['test_loss'].append(outputs.history['val_loss'][0])\n",
    "        results['test_mse'].append(outputs.history['val_mean_squared_error'][0])\n",
    "        train_loss = round(results['train_loss'][-1],3)\n",
    "        test_loss = round(results['test_loss'][-1],3)\n",
    "        \n",
    "        print(\"-\"*80)\n",
    "        process_time = round((time.time()-start_time) / 60.0, 1)\n",
    "        print(f\"[{process_time} mins] epoch: {epoch} | train loss:{train_loss} | test loss: {test_loss}\")\n",
    "        \n",
    "plt.plot(results['train_loss'], label='train_loss')\n",
    "plt.plot(results['test_loss'], label='test_loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pressures[1, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.zeros((4,4))\n",
    "np.fill_diagonal(m, 0.0001)\n",
    "x = np.array([0, 0, 0, 0])\n",
    "energy_function = 0\n",
    "lstsq_energies = []\n",
    "for i in range(10000):\n",
    "    error_vector = A @ x - d\n",
    "    energy_function = (1/2) * error_vector.T @ error_vector\n",
    "    lstsq_energies.append(energy_function)\n",
    "    gradient_vector = A.T @ error_vector\n",
    "    scaled_gradient = -m @ gradient_vector\n",
    "    x_new = x + scaled_gradient\n",
    "    x = x_new\n",
    "\n",
    "np.concatenate([x[:,0],model.pressures[1, 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstsq_loss_without_tf = lstsq_energies[-1]\n",
    "print(\"Loss without using tensorflow is \", lstsq_loss_without_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = d\n",
    "n_dim = 4\n",
    "n_training_steps_per_epoch = 1\n",
    "x_train = np.zeros((n_training_steps_per_epoch,n_dim))\n",
    "NET_LEARNING_RATE = 1e-2\n",
    "NET_EPOCHS = 1000\n",
    "NET_BATCH_SIZE = 1\n",
    "\n",
    "class LinearSystemSolution(tf.keras.Model):\n",
    "    def __init__(self, n_input_dimension, A, b, **kwargs):\n",
    "        super(LinearSystemSolution, self).__init__(**kwargs)\n",
    "        self.solution = tf.Variable(initial_value=tf.zeros((\n",
    "        n_input_dimension,1), dtype=tf.float64),\n",
    "        trainable= True ,\n",
    "        dtype=tf.float64,\n",
    "        shape=(n_input_dimension,1))\n",
    "        self.A = tf.convert_to_tensor(A)\n",
    "        self.b = tf.convert_to_tensor(b)\n",
    "    def call(self, x, training=True):\n",
    "        error = tf.matmul(self.A, self.solution) - self.b\n",
    "        self.add_loss(tf.reduce_sum(tf.square(error))/2)\n",
    "        return self.solution\n",
    "    \n",
    "network = LinearSystemSolution(n_dim, A, b)\n",
    "network.compile(optimizer=tf.optimizers.SGD(learning_rate=NET_LEARNING_RATE))\n",
    "# callbacks = [LossAndErrorPrintingCallback()]\n",
    "lstsq_historian = network.fit(x_train, \n",
    "                              epochs=NET_EPOCHS,\n",
    "                              verbose=1, \n",
    "                              batch_size=NET_BATCH_SIZE, \n",
    "                            #   callbacks=callbacks\n",
    "                              )\n",
    "lstsq_energies[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstsq_loss_with_tf = (lstsq_historian.history[\"loss\"][-1])\n",
    "print(\"Loss using tensorflow is \", lstsq_loss_with_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.semilogy(lstsq_historian.history[\"loss\"], \"x\",\n",
    "label = \"with tf\", markevery= 5)\n",
    "ax.semilogy(lstsq_energies, label = \"without tf\")\n",
    "ax.set_title(\"Loss: Ordinary Least Squares Problem\")\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2116d95755a7ead68517cc9ba299794c4bd48974193acd37c3254ab5a44c419e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
